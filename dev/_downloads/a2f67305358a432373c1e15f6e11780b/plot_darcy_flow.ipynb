{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# A simple Darcy-Flow dataset\nAn introduction to the small Darcy-Flow example dataset we ship with the package.\n\nThe Darcy-Flow problem is a fundamental partial differential equation (PDE) in fluid mechanics\nthat describes the flow of a fluid through a porous medium. In this tutorial, we explore the\ndataset structure and visualize how the data is processed for neural operator training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Import the library\nWe first import our `neuralop` library and required dependencies.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom neuralop.data.datasets import load_darcy_flow_small\nfrom neuralop.layers.embeddings import GridEmbedding2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Load the dataset\nTraining samples are 16x16 and we load testing samples at both \n16x16 and 32x32 (to test resolution invariance).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_loader, test_loaders, data_processor = load_darcy_flow_small(\n        n_train=100, batch_size=4, \n        test_resolutions=[16, 32], n_tests=[50, 50], test_batch_sizes=[4, 2],\n        )\n\ntrain_dataset = train_loader.dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Visualizing the data\nLet's examine the shape and structure of our dataset at different resolutions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for res, test_loader in test_loaders.items():\n    print(f\"Resolution: {res}\")\n    # Get first batch\n    batch = next(iter(test_loader))\n    x = batch['x']  # Input\n    y = batch['y']  # Output\n\n    print(f'Testing samples for resolution {res} have shape {x.shape[1:]}')\n\n\ndata = train_dataset[0]\nx = data['x']\ny = data['y']\n\nprint(f'Training samples have shape {x.shape[1:]}')\n\n# Which sample to view\nindex = 0\n\ndata = train_dataset[index]\ndata = data_processor.preprocess(data, batched=False)\n\n# The first step of the default FNO model is a grid-based\n# positional embedding. We will add it manually here to\n# visualize the channels appended by this embedding.\npositional_embedding = GridEmbedding2D(in_channels=1)\n# At train time, data will be collated with a batch dimension.\n# We create a batch dimension to pass into the embedding, then re-squeeze\nx = positional_embedding(data['x'].unsqueeze(0)).squeeze(0)\ny = data['y']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Visualizing the processed data\nWe can see how the positional embedding adds coordinate information to our input data.\nThis helps the neural operator understand spatial relationships in the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(7, 7))\nax = fig.add_subplot(2, 2, 1)\nax.imshow(x[0], cmap='gray')\nax.set_title('Input x')\nax = fig.add_subplot(2, 2, 2)\nax.imshow(y.squeeze())\nax.set_title('Output y')\nax = fig.add_subplot(2, 2, 3)\nax.imshow(x[1])\nax.set_title('Positional embedding: x-coordinates')\nax = fig.add_subplot(2, 2, 4)\nax.imshow(x[2])\nax.set_title('Positional embedding: y-coordinates')\nfig.suptitle('Visualizing one input sample with positional embeddings', y=0.98)\nplt.tight_layout()\nfig.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}