{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# DISCO Convolutions\n\nThis tutorial demonstrates Discrete-Continuous (DISCO) convolutions, which are\nthe building blocks of localized neural operator frameworks. DISCO convolutions\nare crucial for:\n\n- Learning localized patterns in data\n- Handling both equidistant and unstructured grids\n- Enabling efficient computation on irregular domains\n- Bridging discrete and continuous representations\n\nThe tutorial covers various DISCO convolution types and their applications\nin neural operator architectures.\n    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nPreparation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport math\nfrom functools import partial\n\nfrom matplotlib import image\n\nfrom torch_harmonics.quadrature import (\n    legendre_gauss_weights,\n    lobatto_weights,\n    clenshaw_curtiss_weights,\n)\n\nimport matplotlib.pyplot as plt\n\ncmap = \"inferno\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nfrom neuralop.layers.discrete_continuous_convolution import (\n    DiscreteContinuousConv2d,\n    DiscreteContinuousConvTranspose2d,\n    EquidistantDiscreteContinuousConv2d,\n    EquidistantDiscreteContinuousConvTranspose2d,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nLet's start by loading an example image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "os.system(\n    \"curl https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Albert_Einstein_Head.jpg/360px-Albert_Einstein_Head.jpg -o ./einstein.jpg\"\n)\n\nnx = 90\nny = 120\n\nimg = image.imread(\"./einstein.jpg\")\ndata = nn.functional.interpolate(\n    torch.from_numpy(img).unsqueeze(0).unsqueeze(0), size=(ny, nx)\n).squeeze()\nplt.imshow(data, cmap=cmap)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nLet's create a grid on which the data lives\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_in = torch.linspace(0, 2, nx)\ny_in = torch.linspace(0, 3, ny)\n\nx_in, y_in = torch.meshgrid(x_in, y_in, indexing=\"ij\")\ngrid_in = torch.stack([x_in.reshape(-1), y_in.reshape(-1)])\n\n# compute the correct quadrature weights\n# IMPORTANT: this needs to be done right in order for the DISCO convolution to be normalized proeperly\nw_x = 2 * torch.ones_like(x_in) / nx\nw_y = 3 * torch.ones_like(y_in) / ny\nq_in = (w_x * w_y).reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nVisualize the grid\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(\n    figsize=(4, 6),\n)\nplt.scatter(grid_in[0], grid_in[1], s=0.2)\nplt.xlim(0, 2)\nplt.ylim(0, 3)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nFormat data into the same format and plot it on the grid\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = data.permute(1, 0).flip(1).reshape(-1)\n\nplt.figure(figsize=(4,6))\nplt.tripcolor(grid_in[0], grid_in[1], data, cmap=cmap)\n# plt.colorbar()\nplt.xlim(0, 2)\nplt.ylim(0, 3)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nFor the convolution output we require an output mesh\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nxo = 90\nnyo = 120\n\nx_out = torch.linspace(0, 2, nxo)\ny_out = torch.linspace(0, 3, nyo)\n\nx_out, y_out = torch.meshgrid(x_out, y_out, indexing=\"ij\")\ngrid_out = torch.stack([x_out.reshape(-1), y_out.reshape(-1)])\n\n# compute the correct quadrature weights\nw_x = 2 * torch.ones_like(x_out) / nxo\nw_y = 3 * torch.ones_like(y_out) / nyo\nq_out = (w_x * w_y).reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nInitialize the convolution and set the weights to something resembling an edge filter/finit differences\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "conv = DiscreteContinuousConv2d(\n    1,\n    1,\n    grid_in=grid_in,\n    grid_out=grid_out,\n    quadrature_weights=q_in,\n    kernel_shape=[2, 4],\n    radius_cutoff=5 / nyo,\n    periodic=False,\n).float()\n\n# initialize a kernel resembling an edge filter\nw = torch.zeros_like(conv.weight)\nw[0, 0, 1] = 1.0\nw[0, 0, 3] = -1.0\nconv.weight = nn.Parameter(w)\npsi = conv.get_local_filter_matrix()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nApply the DISCO convolution to the data and plot it\nin order to compute the convolved image, we need to first bring it into the right shape with `batch_size x n_channels x n_grid_points`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "out = conv(data.reshape(1, 1, -1))\n\nprint(out.shape)\n\nplt.figure(figsize=(4,6))\nplt.imshow(torch.flip(out.squeeze().detach().reshape(nxo, nyo).transpose(0,1), dims=(-2, )), cmap=cmap)\nplt.colorbar()\nplt.show()\n\nout1 = torch.flip(out.squeeze().detach().reshape(nxo, nyo).transpose(0, 1), dims=(-2,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nDo the same but on an equidistant grid\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "conv_equi = EquidistantDiscreteContinuousConv2d(\n    1,\n    1,\n    (nx, ny),\n    (nxo, nyo),\n    kernel_shape=[2, 4],\n    radius_cutoff=5 / nyo,\n    domain_length=[2, 3],\n)\n\n# initialize a kernel resembling an edge filter\nw = torch.zeros_like(conv.weight)\nw[0, 0, 1] = 1.0\nw[0, 0, 3] = -1.0\nconv_equi.weight = nn.Parameter(w)\n\ndata = nn.functional.interpolate(\n    torch.from_numpy(img).unsqueeze(0).unsqueeze(0), size=(ny, nx)\n).float()\n\nout_equi = conv_equi(data)\n\nprint(out_equi.shape)\n\nplt.figure(figsize=(4,6))\nplt.imshow(out_equi.squeeze().detach(), cmap=cmap)\nplt.colorbar()\nplt.show()\n\nout2 = out_equi.squeeze().detach()\n\nprint(out2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nVisualize the local filter matrix\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4,6))\nplt.imshow(conv_equi.get_local_filter_matrix()[0].detach(), cmap=cmap)\nplt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nTest the transpose convolution\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "convt = DiscreteContinuousConvTranspose2d(\n    1,\n    1,\n    grid_in=grid_out,\n    grid_out=grid_in,\n    quadrature_weights=q_out,\n    kernel_shape=[2, 4],\n    radius_cutoff=3 / nyo,\n    periodic=False,\n).float()\n\n# initialize a flat\nw = torch.zeros_like(conv.weight)\nw[0, 0, 0] = 1.0\nw[0, 0, 1] = 1.0\nw[0, 0, 2] = 1.0\nw[0, 0, 3] = 1.0\nconvt.weight = nn.Parameter(w)\n\ndata = (\n    nn.functional.interpolate(\n        torch.from_numpy(img).unsqueeze(0).unsqueeze(0), size=(ny, nx)\n    )\n    .squeeze().float()\n    .permute(1, 0).flip(1).reshape(-1)\n)\nout = convt(data.reshape(1, 1, -1))\n\nprint(out.shape)\n\nplt.figure(figsize=(4,6))\nplt.imshow(torch.flip(out.squeeze().detach().reshape(nx, ny).transpose(0,1), dims=(-2, )), cmap=cmap)\nplt.colorbar()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nTest the equidistant transpose convolution\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "convt_equi = EquidistantDiscreteContinuousConvTranspose2d(\n    1,\n    1,\n    (nxo, nyo),\n    (nx, ny),\n    kernel_shape=[2, 4],\n    radius_cutoff=3 / nyo,\n    domain_length=[2, 3],\n)\n\n# initialize a flat\nw = torch.zeros_like(convt_equi.weight)\nw[0, 0, 0] = 1.0\nw[0, 0, 1] = 1.0\nw[0, 0, 2] = 1.0\nw[0, 0, 3] = 1.0\nconvt_equi.weight = nn.Parameter(w)\n\ndata = nn.functional.interpolate(\n    torch.from_numpy(img).unsqueeze(0).unsqueeze(0), size=(nyo, nxo)\n).float()\nout_equi = convt_equi(data)\n\nprint(out_equi.shape)\n\nplt.figure(figsize=(4,6))\nplt.imshow(out_equi.squeeze().detach(), cmap=cmap)\nplt.colorbar()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}