{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Resampling layers\n\nWhen working with neural operators, we often need to change the resolution of our data.\nFor some architectures, like the FNO, this is handled automatically due to the \nresolution-invariant nature of the Fourier domain.\n\nHowever, for other architectures, like the U-Net, we need to explicitly upsample and downsample\nthe data as it flows through the network. The ``neuralop.layers.resample`` function provides a \nconvenient way to do this.\n\nIn this example, we'll demonstrate how to use the ``resample`` function to upsample and downsample\na sample from a Gaussian Random Field, which serves as a better visual tool than piecewise\nconstant data for observing the effects of interpolation.\n\nFor 1D and 2D inputs, the ``resample`` function uses PyTorch\u2019s built-in spatial interpolators \nfor efficiency, applying linear interpolation for 1D data and bicubic interpolation for 2D data directly \nin the spatial domain. \n\nFor 3D or higher-dimensional inputs, the ``resample`` function switches to a spectral interpolation method \nbased on the Fourier transform. The input is transformed into the frequency domain using a real n-dimensional FFT, \nwhich decomposes the signal into its frequency components. By resizing this frequency representation and \nthen applying an inverse FFT, the function achieves smooth, alias-free interpolation \nthat preserves the signal\u2019s overall structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport matplotlib.pyplot as plt\nfrom neuralop.layers.resample import resample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nFirst, let's generate a data input. We create a high-resolution Gaussian Random Field (GRF), which\nis a smooth, continuous signal, making it ideal for visualizing the effects of resampling.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = \"cpu\"\n\n\ndef generate_grf(shape, alpha=2.5, device=\"cpu\"):\n    \"\"\"Generates a 2D Gaussian Random Field.\n\n    Parameters\n    ----------\n    shape : tuple\n        The desired output shape (height, width).\n    alpha : float, optional\n        A parameter controlling the smoothness of the field.\n        Higher alpha leads to smoother fields, by default 2.5.\n    device : str, optional\n        The device to create the tensor on, by default 'cpu'.\n\n    Returns\n    -------\n    torch.Tensor\n        A 4D tensor of shape (1, 1, height, width) containing the GRF.\n    \"\"\"\n    n, m = shape\n    freq_x = torch.fft.fftfreq(n, d=1 / n, device=device).view(-1, 1)\n    freq_y = torch.fft.fftfreq(m, d=1 / m, device=device).view(1, -1)\n\n    norm_sq = freq_x**2 + freq_y**2\n    norm_sq[0, 0] = 1.0  # Avoid division by zero\n\n    # Generate white noise in frequency domain\n    noise = torch.randn(n, m, dtype=torch.cfloat, device=device)\n\n    # Apply a power-law filter\n    filtered_noise = noise * (norm_sq ** (-alpha / 2.0))\n\n    # Inverse FFT to get the spatial field\n    field = torch.fft.ifft2(filtered_noise).real\n\n    # Normalize to [0, 1] for visualization\n    field = (field - field.min()) / (field.max() - field.min())\n\n    return field.unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n\n\n# Generate a 128x128 sample as our ground truth\nhigh_res = 128\nhigh_res_data = generate_grf((high_res, high_res), device=device)\n\n# Define the low resolution we want to simulate (4x downsampling)\nlow_res = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nNow, let's use the ``resample`` function to simulate downsampling and upsampling operations.\nThis could for instance be used in the encoder and decoder of a U-Net architecture.\nThe function takes an input tensor, a `scale_factor`, and a list of\n`axis` dimensions to which the resampling is applied.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# To downsample from 128x128 to 32x32, we need a scale factor of 32/128 = 0.25\ndownsample_factor = low_res / high_res\ndownsampled_data = resample(high_res_data, downsample_factor, [2, 3])\n\n# To upsample from 32x32 back to 128x128, we need a scale factor of 128/32 = 4\nupsample_factor = high_res / low_res\nupsampled_data = resample(downsampled_data, upsample_factor, [2, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nFinally, let's visualize the results to see the effect of the ``resample`` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(14, 6))\nplt.subplots_adjust(wspace=0.04)\nfig.suptitle(\"Resampling a Gaussian Random Field\", fontsize=24)\n\n# Plot the original high-resolution data\nim1 = axs[0].imshow(high_res_data.squeeze().cpu().numpy(), cmap=\"viridis\", vmin=0, vmax=1)\naxs[0].set_title(f\"High-Res Data ({high_res}x{high_res})\", fontsize=16, fontweight=\"bold\")\ncbar1 = fig.colorbar(im1, ax=axs[0], fraction=0.046, pad=0.04, ticks=[0, 0.5, 1])\ncbar1.ax.tick_params(labelsize=14)\n\n# Plot the downsampled data\nim2 = axs[1].imshow(downsampled_data.squeeze().cpu().numpy(), cmap=\"viridis\", vmin=0, vmax=1)\naxs[1].set_title(f\"Downsampled (x{downsample_factor}) ({low_res}x{low_res})\", fontsize=16, fontweight=\"bold\")\ncbar2 = fig.colorbar(im2, ax=axs[1], fraction=0.046, pad=0.04, ticks=[0, 0.5, 1])\ncbar2.ax.tick_params(labelsize=14)\n\n# Plot the upsampled data\nim3 = axs[2].imshow(upsampled_data.squeeze().cpu().numpy(), cmap=\"viridis\", vmin=0, vmax=1)\naxs[2].set_title(f\"Upsampled Back (x{upsample_factor:.0f}) ({high_res}x{high_res})\", fontsize=16, fontweight=\"bold\")\ncbar3 = fig.colorbar(im3, ax=axs[2], fraction=0.046, pad=0.04, ticks=[0, 0.5, 1])\ncbar3.ax.tick_params(labelsize=14)\n\n# Hide axis ticks for a cleaner look\nfor ax in axs.flat:\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout(rect=[0, 0.03, 1, 1.08])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nThe ``resample`` function effectively changes the resolution of the data.\nNotice that the upsampled image on the right is a faithful, if slightly blurrier,\nreconstruction of the original. This is because the downsampling step is lossy;\nhigh-frequency details are lost and cannot be perfectly recovered.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}