{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Training an FNO on Darcy-Flow\n\nWe train a Fourier Neural Operator (FNO) on our small `Darcy-Flow example <sphx_glr_auto_examples_data_plot_darcy_flow.py>`.\n\nThis tutorial demonstrates the complete workflow of training a neural operator:\n1. Loading and preprocessing the Darcy-Flow dataset\n2. Creating an FNO model architecture\n3. Setting up training components (optimizer, scheduler, losses)\n4. Training the model\n5. Evaluating predictions and zero-shot super-resolution\n\nNote that this dataset is much smaller than one we would use in practice. The small Darcy-flow is an example built to\nbe trained on a CPU in a few seconds, whereas normally we would train on one or multiple GPUs. \n\nThe FNO's key advantage is its resolution invariance - it can make predictions at different resolutions\nwithout retraining, which we will demonstrate in the zero-shot super-resolution section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Import dependencies\nWe import the necessary modules from `neuralop` for training a Fourier Neural Operator\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport matplotlib.pyplot as plt\nimport sys\nfrom neuralop.models import FNO\nfrom neuralop import Trainer\nfrom neuralop.training import AdamW\nfrom neuralop.data.datasets import load_darcy_flow_small\nfrom neuralop.utils import count_model_params\nfrom neuralop import LpLoss, H1Loss\n\ndevice = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Loading the Darcy-Flow dataset\nWe load the small Darcy-Flow dataset with multiple resolutions for training and testing.\nThe dataset contains permeability fields (input) and pressure fields (output).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_loader, test_loaders, data_processor = load_darcy_flow_small(\n        n_train=1000, batch_size=32, \n        test_resolutions=[16, 32], n_tests=[100, 50],\n        test_batch_sizes=[32, 32],\n)\ndata_processor = data_processor.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Creating the FNO model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = FNO(n_modes=(8, 8),\n             in_channels=1, \n             out_channels=1,\n             hidden_channels=32, \n             projection_channel_ratio=2)\nmodel = model.to(device)\n\n# Count and display the number of parameters\nn_params = count_model_params(model)\nprint(f'\\nOur model has {n_params} parameters.')\nsys.stdout.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Creating the optimizer and scheduler\nWe use AdamW optimizer with weight decay for regularization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(), \n                                lr=8e-3, \n                                weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Setting up loss functions\nWe use H1 loss for training and L2 loss for evaluation\nH1 loss is particularly good for PDE problems as it penalizes both function values and gradients\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "l2loss = LpLoss(d=2, p=2)  # L2 loss for function values\nh1loss = H1Loss(d=2)       # H1 loss includes gradient information\n\ntrain_loss = h1loss\neval_losses={'h1': h1loss, 'l2': l2loss}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Training the model\nWe display the training configuration and then train the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('\\n### MODEL ###\\n', model)\nprint('\\n### OPTIMIZER ###\\n', optimizer)\nprint('\\n### SCHEDULER ###\\n', scheduler)\nprint('\\n### LOSSES ###')\nprint(f'\\n * Train: {train_loss}')\nprint(f'\\n * Test: {eval_losses}')\nsys.stdout.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Creating the trainer\nWe create a Trainer object that handles the training loop, evaluation, and logging\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model=model, n_epochs=20,\n                  device=device,\n                  data_processor=data_processor,\n                  wandb_log=False,        # Disable Weights & Biases logging for this tutorial\n                  eval_interval=3,       # Evaluate every 3 epochs\n                  use_distributed=False,  # Single GPU/CPU training\n                  verbose=True)          # Print training progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Training the model\nWe train the model on our Darcy-Flow dataset. The trainer will:\n1. Run the forward pass through the FNO\n2. Compute the H1 loss\n3. Backpropagate and update weights\n4. Evaluate on test data every 3 epochs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.train(train_loader=train_loader,\n              test_loaders=test_loaders,\n              optimizer=optimizer,\n              scheduler=scheduler, \n              regularizer=False, \n              training_loss=train_loss,\n              eval_losses=eval_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\nVisualizing predictions\n------------------------\nLet's take a look at what our model's predicted outputs look like. \nWe wll compare the inputs, ground-truth outputs, and model predictions side by side.\n\nNote that in this example, we train on a very small resolution for\na very small number of epochs. In practice, we would train at a larger \nresolution on many more samples.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "test_samples = test_loaders[16].dataset\n\nfig = plt.figure(figsize=(7, 7))\nfor index in range(3):\n    data = test_samples[index]\n    data = data_processor.preprocess(data, batched=False)\n    \n    # Input\n    x = data['x']\n    # Ground-truth output\n    y = data['y']\n    # Model prediction\n    out = model(x.unsqueeze(0))\n\n    # Plot input \n    ax = fig.add_subplot(3, 3, index*3 + 1)\n    ax.imshow(x[0], cmap='gray')\n    if index == 0: \n        ax.set_title('Input x')\n    plt.xticks([], [])\n    plt.yticks([], [])\n\n    # Plot ground-truth output\n    ax = fig.add_subplot(3, 3, index*3 + 2)\n    ax.imshow(y.squeeze())\n    if index == 0: \n        ax.set_title('Ground-truth output')\n    plt.xticks([], [])\n    plt.yticks([], [])\n\n    # Plot model prediction\n    ax = fig.add_subplot(3, 3, index*3 + 3)\n    ax.imshow(out.squeeze().detach().numpy())\n    if index == 0: \n        ax.set_title('Model prediction')\n    plt.xticks([], [])\n    plt.yticks([], [])\n\nfig.suptitle('FNO predictions on 16x16 Darcy-Flow data', y=0.98)\nplt.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n.. zero_shot :\nZero-shot super-resolution evaluation\n-------------------------------------\nOne of the key advantages of neural operators is their resolution invariance.\nThe FNO's invariance to the discretization of input data means we can natively \nmake predictions on higher-resolution inputs and get higher-resolution outputs\nwithout retraining the model!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "test_samples = test_loaders[32].dataset\n\nfig = plt.figure(figsize=(7, 7))\nfor index in range(3):\n    data = test_samples[index]\n    data = data_processor.preprocess(data, batched=False)\n    \n    # Input at higher-resolution\n    x = data['x']\n    # Ground-truth output at higher-resolution\n    y = data['y']\n    # Model prediction at higher-resolution\n    out = model(x.unsqueeze(0))\n\n    # Plot input at higher-resolution\n    ax = fig.add_subplot(3, 3, index*3 + 1)\n    ax.imshow(x[0], cmap='gray')\n    if index == 0: \n        ax.set_title('Input at 32x32')\n    plt.xticks([], [])\n    plt.yticks([], [])\n\n    # Plot ground-truth output at higher-resolution\n    ax = fig.add_subplot(3, 3, index*3 + 2)\n    ax.imshow(y.squeeze())\n    if index == 0: \n        ax.set_title('Ground-truth at 32x32')\n    plt.xticks([], [])\n    plt.yticks([], [])\n\n    # Plot model prediction at higher-resolution\n    ax = fig.add_subplot(3, 3, index*3 + 3)\n    ax.imshow(out.squeeze().detach().numpy())\n    if index == 0: \n        ax.set_title('FNO prediction at 32x32')\n    plt.xticks([], [])\n    plt.yticks([], [])\n\nfig.suptitle('Zero-shot super-resolution: 16x16 \u2192 32x32', y=0.98)\nplt.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Understanding zero-shot super-resolution\nWe only trained the model on data at a resolution of 16x16, and with no modifications \nor special prompting, we were able to perform inference on higher-resolution input data \nand get higher-resolution predictions! This is a powerful capability of neural operators.\n\nIn practice, we often want to evaluate neural operators at multiple resolutions to track \na model's zero-shot super-resolution performance throughout training. That's why many of \nour datasets, including the small Darcy-flow we showcased, are parameterized with a list \nof `test_resolutions` to choose from. \n\nNote: These predictions may be noisier than we would expect for a model evaluated \nat the same resolution at which it was trained. This is because the model hasn't seen\nthe higher-frequency patterns present in the 32x32 data during training. However, this\ndemonstrates the fundamental resolution invariance of neural operators. \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}