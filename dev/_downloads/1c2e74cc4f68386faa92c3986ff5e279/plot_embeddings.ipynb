{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Grid Embeddings\n\nGrid embeddings encode spatial coordinates in neural operators, helping models understand geometric structure. This tutorial shows how to use:\n\n- 2D and N-dimensional grid embeddings\n- Custom coordinate systems\n- Different embedding types for various domains\n\nGrid embeddings are key for PDE solving, computer vision, and other spatially-structured problems. They add coordinate information and help neural operators learn spatial relationships.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Import dependencies\nWe import the necessary modules for working with grid embeddings\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\nimport matplotlib.pyplot as plt\nimport torch\n\ndevice = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Understanding grid embeddings\nAs we show in `small_darcy_vis`, we apply a 2D grid positional encoding to our data\nbefore passing it into the FNO. This embedding has been shown to improve model performance\nin a variety of applications by providing spatial context to the neural operator.\n\nLet's walk through its use. We start with a function that gives the coordinates of the\nbottom-left corners of each pixel in a grid:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from neuralop.layers.embeddings import regular_grid_2d\n\ngrid_2d = (\n    torch.stack(regular_grid_2d(spatial_dims=(8, 8))).permute(1, 2, 0).view(-1, 2)\n)  # reshape into (64, 2)\n\n# Visualize the 2D grid coordinates\nplt.scatter(grid_2d[:, 0], grid_2d[:, 1], color=\"orange\", label=\"2D regular grid\")\nplt.legend()\nplt.title(\"2D Grid Coordinates\")\nplt.xlabel(\"X coordinate\")\nplt.ylabel(\"Y coordinate\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Applying grid embeddings to data\nIn practice, we concatenate these two channels, representing the x- and y-coordinates\nof each pixel in an example, after the channels which encode physical variables\nin our PDE problems. This provides spatial context to the neural operator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from neuralop.data.datasets import load_darcy_flow_small\nfrom neuralop.layers.embeddings import GridEmbedding2D\n\n# Load the Darcy-Flow dataset for demonstration\n_, test_loaders, _ = load_darcy_flow_small(\n    n_train=10,\n    batch_size=1,\n    test_resolutions=[16, 32],\n    n_tests=[16, 16],\n    test_batch_sizes=[2, 2],\n    encode_output=False,\n)\n\n# Get a sample from the dataset\nloader_16 = test_loaders[16]\nexample = next(iter(loader_16))\nx = example[\"x\"]\nprint(f\"One batch of x is of shape: {x.shape}\")\n\n# Note: our Darcy dataset is generated on the unit square, but our grid\n# embedding's boundaries are configurable.\ngrid_embedding = GridEmbedding2D(in_channels=1, grid_boundaries=[[0, 1], [0, 1]])\nx = grid_embedding(x)\nprint(f\"After embedding, x is of shape: {x.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Visualizing the embedded data\nWe can visualize how the grid embedding adds coordinate information to our data.\nThe embedding adds two channels: one for x-coordinates and one for y-coordinates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Grab the first element of the batch\nx = x[0]\nfig = plt.figure(figsize=(7, 7))\n\n# Plot the original input data\nax = fig.add_subplot(2, 2, 1)\nax.imshow(x[0], cmap=\"gray\")\nax.set_title(\"Input x\")\n\n# Plot the x-coordinate embedding\nax = fig.add_subplot(2, 2, 3)\nax.imshow(x[1])\nax.set_title(\"x-coordinate embedding\")\n\n# Plot the y-coordinate embedding\nax = fig.add_subplot(2, 2, 4)\nax.imshow(x[2])\nax.set_title(\"y-coordinate embedding\")\n\nfig.suptitle(\"Visualizing one input sample with positional embeddings\", y=0.98)\nplt.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Discretization invariance\nOur embeddings are also designed with discretization-invariance in mind.\nWithout any changes, we can apply the same embedding to higher-resolution data.\nThis is crucial for neural operators that need to work at different resolutions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loader_32 = test_loaders[32]\nexample = next(iter(loader_32))\nx = example[\"x\"]\nprint(f\"One batch of x is of shape: {x.shape}\")\n\n# Apply the same grid embedding to higher-resolution data\nx = grid_embedding(x)\nprint(f\"After embedding, x is of shape: {x.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Visualizing higher-resolution embeddings\nWe can see how the grid embedding scales to different resolutions.\nThe coordinate information is automatically adjusted to the new grid size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Grab the first element of the batch\nx = x[0]\nfig = plt.figure(figsize=(7, 7))\n\n# Plot the original input data\nax = fig.add_subplot(2, 2, 1)\nax.imshow(x[0], cmap=\"gray\")\nax.set_title(\"Input x\")\n\n# Plot the x-coordinate embedding\nax = fig.add_subplot(2, 2, 3)\nax.imshow(x[1])\nax.set_title(\"x-coordinate embedding\")\n\n# Plot the y-coordinate embedding\nax = fig.add_subplot(2, 2, 4)\nax.imshow(x[2])\nax.set_title(\"y-coordinate embedding\")\n\nfig.suptitle(\"Visualizing one input sample with positional embeddings\", y=0.98)\nplt.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Understanding discretization invariance\nThe grid embeddings automatically adapt to different resolutions:\n1. The coordinate values are normalized to the same range regardless of resolution\n2. The spatial relationships are preserved across different grid sizes\n3. This allows neural operators to work seamlessly at different resolutions\n4. The same model can be applied to data of varying spatial discretization\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Working with 3D grid embeddings\nLet's also demonstrate how to embed a 3D tensor.\nThis is useful for problems involving 3D spatial data, such as:\n- 3D fluid dynamics\n- Volumetric medical imaging\n- 3D material science problems\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from neuralop.layers.embeddings import GridEmbeddingND\n\n# Create a 3D tensor with one channel\ncube_len = 5\nx = torch.randn(1, 1, cube_len, cube_len, cube_len)\nembedding_3d = GridEmbeddingND(in_channels=1, dim=3, grid_boundaries=[[0, 1]] * 3)\n\n# Apply 3D grid embedding\nx = embedding_3d(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <div style=\"margin-top: 3em;\"></div>\n\n## Visualizing 3D grid embeddings\nWe can visualize the 3D embeddings by showing the coordinate information\nin 3D space. Each point represents a spatial location with its coordinates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Grab only the appended positional embedding channels\nx = x[0, 1:, ...].permute(1, 2, 3, 0).view(-1, 3)\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\nplot = ax.scatter(x[:, 0], x[:, 1], x[:, 2], c=x[:, 2])\nfig.colorbar(plot, ax=ax, shrink=0.6)\nax.set_title(\"3D positional encoding, color=Z value\")\nax.set_xlabel(\"X\")\nax.set_ylabel(\"Y\")\nax.set_zlabel(\"Z\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}