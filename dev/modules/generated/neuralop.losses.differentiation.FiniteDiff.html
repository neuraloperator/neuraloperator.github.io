<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>neuralop.losses.differentiation.FiniteDiff &#8212; neuraloperator 1.0.2 documentation</title> 
<link rel="stylesheet" href="../../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/tensorly_style.css?v=a02e9698" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />

  
    <script src="../../_static/documentation_options.js?v=1ed6394b"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
 <script src="../../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="neuralop.losses.differentiation.non_uniform_fd" href="neuralop.losses.differentiation.non_uniform_fd.html" />
    <link rel="prev" title="neuralop.losses.differentiation.FourierDiff" href="neuralop.losses.differentiation.FourierDiff.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        

          <a class="navbar-item" href="../../index.html">
            <img src="../../_static/neuraloperator_logo.png" height="28">
          </a>
          <a class="navbar-item is-hidden-desktop" href="https://github.com/neuraloperator/neuraloperator" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        

          <div class="navbar-start">
            
              <a class="navbar-item" href="../../install.html">
              Install
            </a>
              <a class="navbar-item" href="../../theory_guide/index.html">
              Theory Guide
            </a>
              <a class="navbar-item" href="../../user_guide/index.html">
              User Guide
            </a>
              <a class="navbar-item" href="../api.html">
              API
            </a>
              <a class="navbar-item" href="../../auto_examples/index.html">
              Examples
            </a>
              <a class="navbar-item" href="../../dev_guide/index.html">
              Developer's Guide
            </a>
          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            
            <a class="button is-hidden-touch is-dark" href="https://github.com/neuraloperator/neuraloperator" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
            </a>

            </div> 
          </div> 
        </div> 

      </nav>
      
    </navbar>
  </header>


  <div id="column-container">
  <div class="columns is-mobile is-centered">
	
  
      <div class="column is-10-mobile is-one-third-tablet is-3-desktop is-hidden-mobile" id="sidebar">
    
    <aside class="sticky-nav sidebar-menu">
<div class="sidebar-search">
  <form class="field" id="searchbox" role="search" action="../../search.html" method="get">
    <!-- <label class="label" id="searchlabel">Quick search</label> -->
    <div class="field has-addons">
      <div class="control is-expanded">
        <input class="input" type="text" placeholder="Search the doc" name="q" aria-labelledby="searchlabel autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      </div>
      <div class="control">
        <input class="button is-info" type="submit" value="Go" />
      </div>
    </div>
  </form>
  <script>document.getElementById('searchbox').style.display = "block"</script>

</div>
      
      <div class="sidebar-menu-toc">
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installing NeuralOperator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../theory_guide/index.html">Theory Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/index.html">User Guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">API reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../api.html#models">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#module-neuralop.layers">Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#model-dispatching">Model Dispatching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#training">Training</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../api.html#loss-functions">Loss Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#data">Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#module-neuralop.utils">Utility Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev_guide/index.html">Development guide</a></li>
</ul>
 
      </div>
    </aside>
  </div>
  

  <div class="column main-column">

    
    <div class="main-section">

      
      
      <div class="side-menu-toggle">
        <button class="button" id="toggle-sidebar" onclick="toggle_sidebar()">
          <span class="icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
          <span>menu</span> 
        </button>
      </div>
      

      <div class="container content main-content">
        
  <section id="neuralop-losses-differentiation-finitediff">
<h1><a class="reference internal" href="../api.html#module-neuralop.losses.differentiation" title="neuralop.losses.differentiation"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neuralop.losses.differentiation</span></code></a>.FiniteDiff<a class="headerlink" href="#neuralop-losses-differentiation-finitediff" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="neuralop.losses.differentiation.FiniteDiff">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuralop.losses.differentiation.</span></span><span class="sig-name descname"><span class="pre">FiniteDiff</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">periodic_in_x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">periodic_in_y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">periodic_in_z</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/neuralop/losses/differentiation.html#FiniteDiff"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuralop.losses.differentiation.FiniteDiff" title="Link to this definition"></a></dt>
<dd><p>A unified class for computing finite differences in 1D, 2D, or 3D.</p>
<p>This class provides comprehensive methods for computing derivatives using finite differences
with support for both periodic and non-periodic boundary conditions.</p>
<p>It implements the following high-order finite difference schemes:
- Interior points: Second-order central differences for optimal accuracy
- Periodic boundaries: Uses torch.roll for seamless periodic wrapping.
- Non-periodic boundaries: Uses third-order one-sided differences at boundary points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>dim</strong><span class="classifier">int</span></dt><dd><p>Dimension of the input field. Must be 1, 2, or 3.</p>
</dd>
<dt><strong>h</strong><span class="classifier">float or tuple, optional</span></dt><dd><p>Grid spacing(s) for finite difference calculations, by default 1.0.
- For 1D: single float or tuple with one element
- For 2D: tuple (h_x, h_y) or single float for uniform spacing
- For 3D: tuple (h_x, h_y, h_z) or single float for uniform spacing</p>
</dd>
<dt><strong>periodic_in_x</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to use periodic boundary conditions in x-direction, by default True.
When True, uses torch.roll for efficient periodic wrapping.
When False, uses high-order one-sided differences at boundaries.</p>
</dd>
<dt><strong>periodic_in_y</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to use periodic boundary conditions in y-direction, by default True.
When True, uses torch.roll for efficient periodic wrapping.
When False, uses high-order one-sided differences at boundaries.
Only used for 2D and 3D fields.</p>
</dd>
<dt><strong>periodic_in_z</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to use periodic boundary conditions in z-direction, by default True.
When True, uses torch.roll for efficient periodic wrapping.
When False, uses high-order one-sided differences at boundaries.
Only used for 3D fields.</p>
</dd>
<dt><strong>Available Methods</strong></dt><dd></dd>
<dt><strong>—————-</strong></dt><dd></dd>
<dt><strong>Derivative Methods:</strong></dt><dd></dd>
<dt><strong>- dx(u, order=1): Compute derivative with respect to x</strong></dt><dd></dd>
<dt><strong>- dy(u, order=1): Compute derivative with respect to y (2D/3D only)</strong></dt><dd></dd>
<dt><strong>- dz(u, order=1): Compute derivative with respect to z (3D only)</strong></dt><dd></dd>
<dt><strong>Vector Calculus Operators:</strong></dt><dd></dd>
<dt><strong>- laplacian(u): Compute the Laplacian ∇²f</strong></dt><dd></dd>
<dt><strong>- gradient(u): Compute the gradient ∇f (returns vector field)</strong></dt><dd></dd>
<dt><strong>- divergence(u): Compute the divergence ∇·u (for vector fields)</strong></dt><dd></dd>
<dt><strong>- curl(u): Compute the curl ∇×u (for vector fields, 2D/3D only)</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.curl" title="neuralop.losses.differentiation.FiniteDiff.curl"><code class="xref py py-obj docutils literal notranslate"><span class="pre">curl</span></code></a>(u)</p></td>
<td><p>Compute the curl ∇×u for vector fields.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.divergence" title="neuralop.losses.differentiation.FiniteDiff.divergence"><code class="xref py py-obj docutils literal notranslate"><span class="pre">divergence</span></code></a>(u)</p></td>
<td><p>Compute the divergence ∇·u for vector fields.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.dx" title="neuralop.losses.differentiation.FiniteDiff.dx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dx</span></code></a>(u[, order])</p></td>
<td><p>Compute derivative with respect to x.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.dy" title="neuralop.losses.differentiation.FiniteDiff.dy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dy</span></code></a>(u[, order])</p></td>
<td><p>Compute derivative with respect to y.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.dz" title="neuralop.losses.differentiation.FiniteDiff.dz"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dz</span></code></a>(u[, order])</p></td>
<td><p>Compute derivative with respect to z.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.gradient" title="neuralop.losses.differentiation.FiniteDiff.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(u)</p></td>
<td><p>Compute the gradient ∇f for scalar fields.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.laplacian" title="neuralop.losses.differentiation.FiniteDiff.laplacian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">laplacian</span></code></a>(u)</p></td>
<td><p>Compute the Laplacian ∇²f.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># 1D finite differences</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fd1d</span> <span class="o">=</span> <span class="n">FiniteDiff</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">periodic_in_x</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">du_dx</span> <span class="o">=</span> <span class="n">fd1d</span><span class="o">.</span><span class="n">dx</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>  <span class="c1"># First derivative</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2u_dx2</span> <span class="o">=</span> <span class="n">fd1d</span><span class="o">.</span><span class="n">dx</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Second derivative</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2D finite differences</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fd2d</span> <span class="o">=</span> <span class="n">FiniteDiff</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">periodic_in_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">periodic_in_y</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;ij&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">du_dx</span> <span class="o">=</span> <span class="n">fd2d</span><span class="o">.</span><span class="n">dx</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">du_dy</span> <span class="o">=</span> <span class="n">fd2d</span><span class="o">.</span><span class="n">dy</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">fd2d</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>  <span class="c1"># Returns [du_dx, du_dy]</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 3D finite differences</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fd3d</span> <span class="o">=</span> <span class="n">FiniteDiff</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">periodic_in_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">periodic_in_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">periodic_in_z</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;ij&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>  <span class="c1"># 3D scalar field</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">du_dx</span> <span class="o">=</span> <span class="n">fd3d</span><span class="o">.</span><span class="n">dx</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">du_dy</span> <span class="o">=</span> <span class="n">fd3d</span><span class="o">.</span><span class="n">dy</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">du_dz</span> <span class="o">=</span> <span class="n">fd3d</span><span class="o">.</span><span class="n">dz</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">laplacian</span> <span class="o">=</span> <span class="n">fd3d</span><span class="o">.</span><span class="n">laplacian</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>  <span class="c1"># Sum of all second derivatives</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Vector field operations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vz</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">vx</span><span class="p">,</span> <span class="n">vy</span><span class="p">,</span> <span class="n">vz</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># 3D vector field</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">div_v</span> <span class="o">=</span> <span class="n">fd3d</span><span class="o">.</span><span class="n">divergence</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1"># Scalar field</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">curl_v</span> <span class="o">=</span> <span class="n">fd3d</span><span class="o">.</span><span class="n">curl</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1"># Vector field</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="neuralop.losses.differentiation.FiniteDiff.dx">
<span class="sig-name descname"><span class="pre">dx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/neuralop/losses/differentiation.html#FiniteDiff.dx"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuralop.losses.differentiation.FiniteDiff.dx" title="Link to this definition"></a></dt>
<dd><p>Compute derivative with respect to x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>u</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input tensor</p>
</dd>
<dt><strong>order</strong><span class="classifier">int, optional</span></dt><dd><p>Order of the derivative, by default 1</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Derivative with respect to x</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuralop.losses.differentiation.FiniteDiff.dy">
<span class="sig-name descname"><span class="pre">dy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/neuralop/losses/differentiation.html#FiniteDiff.dy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuralop.losses.differentiation.FiniteDiff.dy" title="Link to this definition"></a></dt>
<dd><p>Compute derivative with respect to y.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>u</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input tensor</p>
</dd>
<dt><strong>order</strong><span class="classifier">int, optional</span></dt><dd><p>Order of the derivative, by default 1</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Derivative with respect to y</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuralop.losses.differentiation.FiniteDiff.dz">
<span class="sig-name descname"><span class="pre">dz</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/neuralop/losses/differentiation.html#FiniteDiff.dz"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuralop.losses.differentiation.FiniteDiff.dz" title="Link to this definition"></a></dt>
<dd><p>Compute derivative with respect to z.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>u</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input tensor</p>
</dd>
<dt><strong>order</strong><span class="classifier">int, optional</span></dt><dd><p>Order of the derivative, by default 1</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>Derivative with respect to z</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuralop.losses.differentiation.FiniteDiff.laplacian">
<span class="sig-name descname"><span class="pre">laplacian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/neuralop/losses/differentiation.html#FiniteDiff.laplacian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuralop.losses.differentiation.FiniteDiff.laplacian" title="Link to this definition"></a></dt>
<dd><p>Compute the Laplacian ∇²f.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>u</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input tensor</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>The Laplacian of the input tensor</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuralop.losses.differentiation.FiniteDiff.gradient">
<span class="sig-name descname"><span class="pre">gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/neuralop/losses/differentiation.html#FiniteDiff.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuralop.losses.differentiation.FiniteDiff.gradient" title="Link to this definition"></a></dt>
<dd><p>Compute the gradient ∇f for scalar fields.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>u</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input scalar field</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>The gradient of the scalar field</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuralop.losses.differentiation.FiniteDiff.divergence">
<span class="sig-name descname"><span class="pre">divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/neuralop/losses/differentiation.html#FiniteDiff.divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuralop.losses.differentiation.FiniteDiff.divergence" title="Link to this definition"></a></dt>
<dd><p>Compute the divergence ∇·u for vector fields.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>u</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input vector field</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>The divergence of the vector field</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuralop.losses.differentiation.FiniteDiff.curl">
<span class="sig-name descname"><span class="pre">curl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">u</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/neuralop/losses/differentiation.html#FiniteDiff.curl"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuralop.losses.differentiation.FiniteDiff.curl" title="Link to this definition"></a></dt>
<dd><p>Compute the curl ∇×u for vector fields.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>u</strong><span class="classifier">torch.Tensor</span></dt><dd><p>Input vector field</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>The curl of the vector field</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="clearer"></div></section>


      </div>

      
        <nav class="pagination" role="navigation" aria-label="pagination">
    
    <a class="button pagination-previous" href="neuralop.losses.differentiation.FourierDiff.html" title="previous page" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span><code class="xref py py-mod docutils literal notranslate"><span class="pre">neuralop.losses.differentiation</span></code>.FourierDiff</span>
    </a>
    
    
    <a class="button pagination-next" href="neuralop.losses.differentiation.non_uniform_fd.html" title="next page" accesskey="n">
        <span><code class="xref py py-mod docutils literal notranslate"><span class="pre">neuralop.losses.differentiation</span></code>.non_uniform_fd </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

      

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2025, Jean Kossaifi, David Pitt, Nikola Kovachki, Zongyi Li and Anima Anandkumar.<br/>
        </div>
    </div>
  </footer>

    </div>

  </div>  

	
    
    <div class="column is-hidden-touch is-2-desktop is-one-fifth-widescreen" id="localtoc-column">

    <aside class="sticky-nav localtoc"> 
        <p class="menu-label"> 
            <span class="icon-text">
                <span class="icon"><i class="fas fa-duotone fa-list"></i></span>
                <span> On this page </span>
            </span>
        </p>

        <div class="menu menu-list localtoc-list">
        <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neuralop.losses.differentiation</span></code>.FiniteDiff</a><ul>
<li><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff"><code class="docutils literal notranslate"><span class="pre">FiniteDiff</span></code></a><ul>
<li><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.dx"><code class="docutils literal notranslate"><span class="pre">FiniteDiff.dx()</span></code></a></li>
<li><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.dy"><code class="docutils literal notranslate"><span class="pre">FiniteDiff.dy()</span></code></a></li>
<li><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.dz"><code class="docutils literal notranslate"><span class="pre">FiniteDiff.dz()</span></code></a></li>
<li><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.laplacian"><code class="docutils literal notranslate"><span class="pre">FiniteDiff.laplacian()</span></code></a></li>
<li><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.gradient"><code class="docutils literal notranslate"><span class="pre">FiniteDiff.gradient()</span></code></a></li>
<li><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.divergence"><code class="docutils literal notranslate"><span class="pre">FiniteDiff.divergence()</span></code></a></li>
<li><a class="reference internal" href="#neuralop.losses.differentiation.FiniteDiff.curl"><code class="docutils literal notranslate"><span class="pre">FiniteDiff.curl()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
    </aside>
    </div>

  

  </div>  
  </div> 

  
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>