<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>neuralop.models.CODANO &#8212; neuraloperator 1.0.2 documentation</title> 
<link rel="stylesheet" href="../../_static/tensorly_style.css">
<link rel="apple-touch-icon" sizes="180x180" href="../../_static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../_static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../../_static/favicon/favicon-16x16.png">
<link rel="manifest" href="../../_static/favicon/site.webmanifest">
<link rel="mask-icon" href="../../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="../../_static/favicon/favicon.ico">
<meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/tensorly_style.css?v=a02e9698" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />

  
    <script src="../../_static/documentation_options.js?v=1ed6394b"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
 <script src="../../_static/navbar_burger.js"></script>
 <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
 
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="neuralop.layers.fno_block.FNOBlocks" href="neuralop.layers.fno_block.FNOBlocks.html" />
    <link rel="prev" title="neuralop.models.FNOGNO" href="neuralop.models.FNOGNO.html" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

  </head>
<body  class="has-navbar-fixed-top">

  <header>
    <navbar>
      <nav class="navbar top-navbar is-fixed-top has-shadow is-flex-wrap-wrap" role="navigation" aria-label="main top navigation">
        <div class="navbar-brand">
        

          <a class="navbar-item" href="../../index.html">
            <img src="../../_static/neuraloperator_logo.png" height="28">
          </a>
          <a class="navbar-item is-hidden-desktop" href="https://github.com/neuraloperator/neuraloperator" target="_blank">
              <span class="icon"><i class="fab fa-github"></i></span>
          </a>

          <a role="button" class="navbar-burger" data-target="top-nav-menu" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>

        </div>
        
        <div class="navbar-menu" id="top-nav-menu">
        

          <div class="navbar-start">
            
              <a class="navbar-item" href="../../install.html">
              Install
            </a>
              <a class="navbar-item" href="../../theory_guide/index.html">
              Theory Guide
            </a>
              <a class="navbar-item" href="../../user_guide/index.html">
              User Guide
            </a>
              <a class="navbar-item" href="../api.html">
              API
            </a>
              <a class="navbar-item" href="../../auto_examples/index.html">
              Examples
            </a>
              <a class="navbar-item" href="../../dev_guide/index.html">
              Developer's Guide
            </a>
          </div>
        
          <div class="navbar-end">
            <div class="navbar-item">
            
            <a class="button is-hidden-touch is-dark" href="https://github.com/neuraloperator/neuraloperator" target="_blank">
              <span class="icon-text">
                <span class="icon is-large">
                  <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
              </span>
            </a>

            </div> 
          </div> 
        </div> 

      </nav>
      
    </navbar>
  </header>


  <div id="column-container">
  <div class="columns is-mobile is-centered">
	
  
      <div class="column is-10-mobile is-one-third-tablet is-3-desktop is-hidden-mobile" id="sidebar">
    
    <aside class="sticky-nav sidebar-menu">
<div class="sidebar-search">
  <form class="field" id="searchbox" role="search" action="../../search.html" method="get">
    <!-- <label class="label" id="searchlabel">Quick search</label> -->
    <div class="field has-addons">
      <div class="control is-expanded">
        <input class="input" type="text" placeholder="Search the doc" name="q" aria-labelledby="searchlabel autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      </div>
      <div class="control">
        <input class="button is-info" type="submit" value="Go" />
      </div>
    </div>
  </form>
  <script>document.getElementById('searchbox').style.display = "block"</script>

</div>
      
      <div class="sidebar-menu-toc">
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installing NeuralOperator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../theory_guide/index.html">Theory Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/index.html">User Guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">API reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../api.html#models">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#module-neuralop.layers">Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#model-dispatching">Model Dispatching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#loss-functions">Loss Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#data">Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#module-neuralop.utils">Utility Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev_guide/index.html">Development guide</a></li>
</ul>
 
      </div>
    </aside>
  </div>
  

  <div class="column main-column">

    
    <div class="main-section">

      
      
      <div class="side-menu-toggle">
        <button class="button" id="toggle-sidebar" onclick="toggle_sidebar()">
          <span class="icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
          <span>menu</span> 
        </button>
      </div>
      

      <div class="container content main-content">
        
  <section id="neuralop-models-codano">
<h1><a class="reference internal" href="../api.html#module-neuralop.models" title="neuralop.models"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neuralop.models</span></code></a>.CODANO<a class="headerlink" href="#neuralop-models-codano" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="neuralop.models.CODANO">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuralop.models.</span></span><span class="sig-name descname"><span class="pre">CODANO</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_variable_codimension=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lifting_channels:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_variable_codimension=32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projection_channels:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_positional_encoding=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">positional_encoding_dim=8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">positional_encoding_modes=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_channel_dim=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">variable_ids=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_horizontal_skip_connection=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">horizontal_skips_map=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers=4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_modes=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_layer_scaling_factors=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_heads=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_scaling_factors=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_module=&lt;class</span> <span class="pre">'neuralop.layers.spectral_convolution.SpectralConv'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_attention=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_linearity=&lt;built-in</span> <span class="pre">function</span> <span class="pre">gelu&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_token_dim=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_channel_attention=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_kwargs={}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">domain_padding=0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_cls_token=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/neuralop/models/codano.html#CODANO"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuralop.models.CODANO" title="Link to this definition"></a></dt>
<dd><p>Codomain Attention Neural Operators (CoDA-NO)</p>
<p>It uses a specialized attention mechanism in the codomain space for data in
infinite dimensional spaces as described in <a class="reference internal" href="#rc0acb03256ea-1" id="id1">[1]</a>. The model treats each input channel as a variable of the physical system
and uses attention mechanism to model the interactions between the variables. The model uses lifting and projection modules
to map the input variables to a higher-dimensional space and then back to the output space. The model also supports positional
encoding and static channel information for additional context of the physical system such as external force or inlet condition.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>n_layers</strong><span class="classifier">int</span></dt><dd><p>The number of codomain attention layers. Default: 4</p>
</dd>
<dt><strong>n_modes</strong><span class="classifier">list</span></dt><dd><p>The number of Fourier modes to use in integral operators in the CoDA-NO block along each dimension.
Example: For a 5-layer 2D CoDA-NO, n_modes=[[16, 16], [16, 16], [16, 16], [16, 16], [16, 16]]</p>
</dd>
<dt><strong>Other parameters</strong></dt><dd></dd>
<dt><strong>—————</strong></dt><dd></dd>
<dt><strong>output_variable_codimension</strong><span class="classifier">int, optional</span></dt><dd><p>The number of output channels (or output codomain dimension) corresponding to each input variable (or input channel).
Example: For an input with 3 variables (channels) and output_variable_codimension=2, the output will have 6 channels (3 variables × 2 codimension). Default: 1</p>
</dd>
<dt><strong>lifting_channels</strong><span class="classifier">int, optional</span></dt><dd><p>Number of intermediate channels in the lifting block.
The lifting module projects each input variable (i.e., each input channel) into a
higher-dimensional space determined by hidden_variable_codimension.
If lifting_channels is None, lifting is not performed and the input channels are
directly used as tokens for codomain attention. Default: 64</p>
</dd>
<dt><strong>hidden_variable_codimension</strong><span class="classifier">int, optional</span></dt><dd><p>The number of hidden channels corresponding to each input variable (or channel). Each input channel is independently lifted
to hidden_variable_codimension channels by the lifting block. Default: 32</p>
</dd>
<dt><strong>projection_channels</strong><span class="classifier">int, optional</span></dt><dd><p>The number of intermediate channels in the projection block of the CODANO.
If projection_channels=None, projection is not performed and the output of
the last CoDA block is returned directly. Default: 64</p>
</dd>
<dt><strong>use_positional_encoding</strong><span class="classifier">bool, optional</span></dt><dd><p>Indicates whether to use variable-specific positional encoding. If True, a learnable positional encoding is concatenated
to each variable (each input channel) before the lifting operation.
The positional encoding used here is a function space generalization of the learnable positional encoding
used in BERT [2]. In CODANO, the positional encoding is a function on domain which is learned directly
in the Fourier Space. Default: False</p>
</dd>
<dt><strong>positional_encoding_dim</strong><span class="classifier">int, optional</span></dt><dd><p>The dimension (number of channels) of the positional encoding learned of each input variable
(i.e., input channel). Default: 8</p>
</dd>
<dt><strong>positional_encoding_modes</strong><span class="classifier">list, optional</span></dt><dd><p>Number of Fourier modes used in positional encoding along each dimension. The positional embeddings are functions and are directly learned
in Fourier space. This parameter must be specified when use_positional_encoding=True.
Example: For a 2D input, positional_encoding_modes could be [16, 16]. Default: None</p>
</dd>
<dt><strong>static_channel_dim</strong><span class="classifier">int, optional</span></dt><dd><p>The number of channels for static information, such as boundary conditions in PDEs. These channels are concatenated with
each variable before the lifting operation and used to provide additional information
regarding the physical setup of the system.
When static_channel_dim &gt; 0, additional information must be provided during the forward pass.
For example, static_channel_dim=1 can be used to provide mask of the domain pointing
a hole or obstacle in the domain. Default: 0</p>
</dd>
<dt><strong>variable_ids</strong><span class="classifier">list[str], optional</span></dt><dd><p>The names of the variables in the dataset.
This parameter is only required when use_positional_encoding=True to initialize learnable
positional embeddings for each unique physical variable in the dataset.</p>
<p>For example:
If the dataset consists of only Navier Stokes equations, the variable_ids=[‘u_x’, ‘u_y’, ‘p’], representing the velocity
components in x and y directions and pressure, respectively. Please note that we consider each input channel as a physical
variable of the PDE.</p>
<p>Please note that the ‘velocity’ variable is composed of two channels (codimension=2) and we have split the velocity field
into two components, i.e., u_x and u_y. And this is to be done for all variable with codimension &gt; 1.</p>
<p>If the dataset consists of multiple PDEs, such as Navier Stokes and Heat equation, the variable_ids=[‘u_x’, ‘u_y’, ‘p’, ‘T’],
where ‘T’ represents the temperature variable for the Heat equation and ‘u_x’, ‘u_y’, ‘p’ are the velocity components and pressure
for the Navier Stokes equations. This is required when we aim to learn a single solver for multiple different PDEs.</p>
<p>This parameter is not required when use_positional_encoding=False. Default: None</p>
</dd>
<dt><strong>per_layer_scaling_factors</strong><span class="classifier">list, optional</span></dt><dd><p>The output scaling factor for each CoDANO_block along each dimension. The output of each of the CoDANO_block
is resampled according to the scaling factor and then passed to the following CoDANO_blocks.
Example: For a 2D input and n_layers=5, per_layer_scaling_factors=[[1, 1], [0.5, 0.5], [1, 1], [2, 2], [1, 1]],
which downsamples the output of the second layer by a factor of 2 and upsamples the output of the fourth layer by a factor of 2.
The resolution of the output of the CODANO model is determined by the product of the scaling factors of all the layers. Default: None</p>
</dd>
<dt><strong>n_heads</strong><span class="classifier">list, optional</span></dt><dd><p>The number of attention heads for each layer.
Example: For a 4-layer CoDA-NO, n_heads=[2, 2, 2, 2]. Default: None (single attention head for each codomain attention block)</p>
</dd>
<dt><strong>attention_scaling_factors</strong><span class="classifier">list, optional</span></dt><dd><p>Scaling factors in the codomain attention mechanism to scale the key and query functions. These scaling factors are used to resample
the key and query function before calculating the attention matrix. It does not have any effect on the value functions
in the codomain attention mechanism, i.e., it does not change the output shape of the block.
Example: For a 5-layer CoDA-NO, attention_scaling_factors=[0.5, 0.5, 0.5, 0.5, 0.5], which downsample the key and query functions,
reducing the resolution by a factor of 2. Default: None (no scaling)</p>
</dd>
<dt><strong>conv_module</strong><span class="classifier">nn.Module, optional</span></dt><dd><p>The convolution module to use in the CoDANO_block. Default: SpectralConv</p>
</dd>
<dt><strong>nonlinear_attention</strong><span class="classifier">bool, optional</span></dt><dd><p>Indicates whether to use a non-linear attention mechanism, employing non-linear key, query, and value operators. Default: False</p>
</dd>
<dt><strong>non_linearity</strong><span class="classifier">callable, optional</span></dt><dd><p>The non-linearity to use in the codomain attention block. Default: F.gelu</p>
</dd>
<dt><strong>attention_token_dim</strong><span class="classifier">int, optional</span></dt><dd><p>The number of channels in each token function. attention_token_dim must divide hidden_variable_codimension. Default: 1</p>
</dd>
<dt><strong>per_channel_attention</strong><span class="classifier">bool, optional</span></dt><dd><p>Indicates whether to use a per-channel attention mechanism in Codomain attention layer. Default: False</p>
</dd>
<dt><strong>enable_cls_token</strong><span class="classifier">bool, optional</span></dt><dd><p>Indicates whether to use a learnable CLASS token during the attention mechanism. We use a function-space generalization of the
learnable [class] token used in vision transformers such as ViT, which is learned directly in Fourier space.
The [class] function is realized on the input grid by performing an inverse Fourier transform of the learned Fourier coefficients.
Then, the [class] token function is added to the set of input token functions before passing to the codomain attention layer. It aggregates
information from all the other tokens through the attention mechanism. The output token corresponding to the [class] token is discarded in the
output of the last CoDA block. Default: False</p>
</dd>
<dt><strong>use_horizontal_skip_connection</strong><span class="classifier">bool, optional</span></dt><dd><p>Indicates whether to use horizontal skip connections, similar to U-shaped architectures. Default: False</p>
</dd>
<dt><strong>horizontal_skips_map</strong><span class="classifier">dict, optional</span></dt><dd><p>A mapping that specifies horizontal skip connections between layers. Only required when use_horizontal_skip_connection=True.
Example: For a 5-layer architecture, horizontal_skips_map={4: 0, 3: 1} creates skip connections from layer 0 to layer 4 and layer 1 to layer 3. Default: None</p>
</dd>
<dt><strong>domain_padding</strong><span class="classifier">float, optional</span></dt><dd><p>The padding factor for each input channel. It zero pads each of the channel. Default: 0.25</p>
</dd>
<dt><strong>layer_kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>Additional arguments for the CoDA blocks. Default: {}</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#neuralop.models.CODANO.forward" title="neuralop.models.CODANO.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(x[, static_channel, input_variable_ids])</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rc0acb03256ea-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>: Rahman, Md Ashiqur, et al. “Pretraining codomain attention neural operators for solving multiphysics pdes.” (2024).</p>
</div>
</div>
<p>NeurIPS 2024. <a class="reference external" href="https://arxiv.org/pdf/2403.12553">https://arxiv.org/pdf/2403.12553</a>.</p>
<div role="list" class="citation-list">
<div class="citation" id="rc0acb03256ea-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>: Devlin, Jacob, et al. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.</p>
</div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="neuralop.models.CODANO.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_channel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_variable_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/neuralop/models/codano.html#CODANO.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuralop.models.CODANO.forward" title="Link to this definition"></a></dt>
<dd><dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x</strong><span class="classifier">torch.Tensor</span></dt><dd><p>input tensor of shape (batch_size, num_inp_var, H, W, …)</p>
</dd>
<dt><strong>static_channel</strong><span class="classifier">torch.Tensor</span></dt><dd><p>static channel tensor of shape (batch_size, static_channel_dim, H, W, …)
These channels provide additional information regarding the physical setup of the system.
Must be provided when <cite>static_channel_dim &gt; 0</cite>.</p>
</dd>
<dt><strong>input_variable_ids</strong><span class="classifier">list[str]</span></dt><dd><p>The names of the variables corresponding to the channels of input ‘x’.
This parameter is required when <cite>use_positional_encoding=True</cite>.</p>
<p>For example, if input x represents and snapshot of the velocity field of a fluid flow, the variable_ids=[‘u_x’, ‘u_y’].
The variable_ids must be in the same order as the channels in the input tensor ‘x’, i.e., variable_ids[0] corresponds to the
first channel of ‘x’, i.e., x[:, 0, …].</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>torch.Tensor</dt><dd><p>output tensor of shape (batch_size, output_variable_codimension*num_inp_var, H, W, …)</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="clearer"></div></section>


      </div>

      
        <nav class="pagination" role="navigation" aria-label="pagination">
    
    <a class="button pagination-previous" href="neuralop.models.FNOGNO.html" title="previous page" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span><code class="xref py py-mod docutils literal notranslate"><span class="pre">neuralop.models</span></code>.FNOGNO</span>
    </a>
    
    
    <a class="button pagination-next" href="neuralop.layers.fno_block.FNOBlocks.html" title="next page" accesskey="n">
        <span><code class="xref py py-mod docutils literal notranslate"><span class="pre">neuralop.layers.fno_block</span></code>.FNOBlocks </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

      

        <footer class="footer">
    <div class="content has-text-centered">
        <div class="block">
          &copy; Copyright 2025, Jean Kossaifi, David Pitt, Nikola Kovachki, Zongyi Li and Anima Anandkumar.<br/>
        </div>
    </div>
  </footer>

    </div>

  </div>  

	
    
    <div class="column is-hidden-touch is-2-desktop is-one-fifth-widescreen" id="localtoc-column">

    <aside class="sticky-nav localtoc"> 
        <p class="menu-label"> 
            <span class="icon-text">
                <span class="icon"><i class="fas fa-duotone fa-list"></i></span>
                <span> On this page </span>
            </span>
        </p>

        <div class="menu menu-list localtoc-list">
        <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neuralop.models</span></code>.CODANO</a><ul>
<li><a class="reference internal" href="#neuralop.models.CODANO"><code class="docutils literal notranslate"><span class="pre">CODANO</span></code></a><ul>
<li><a class="reference internal" href="#neuralop.models.CODANO.forward"><code class="docutils literal notranslate"><span class="pre">CODANO.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
    </aside>
    </div>

  

  </div>  
  </div> 

  
  <script>
    function toggle_sidebar() {
        var element = document.getElementById("sidebar");
        var container = document.getElementById("column-container");
        var localtoccolumn = document.getElementById("localtoc-column");
        element.classList.toggle("hide-tablet");
        element.classList.toggle("is-hidden-mobile");
        container.classList.toggle("sidemenu-hidden");
        localtoccolumn.classList.toggle("is-one-fifth-widescreen");
        localtoccolumn.classList.toggle("is-2-desktop");
        localtoccolumn.classList.toggle("is-3-desktop");
    }
  </script> 



  </body>
</html>