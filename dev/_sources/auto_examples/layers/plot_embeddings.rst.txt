
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/layers/plot_embeddings.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_layers_plot_embeddings.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_layers_plot_embeddings.py:


Grid embeddings
================
``neuralop.layers.embeddings.GridEmbedding2D`` and ``neuralop.layers.embeddings.GridEmbeddingND`` provide interfaces for appending 
grid positional embeddings to your data to improve model generalization. In this example we showcase their use and visualize their outputs.

.. GENERATED FROM PYTHON SOURCE LINES 11-17

.. code-block:: Python

    import random
    import matplotlib.pyplot as plt
    import torch

    device = 'cpu'








.. GENERATED FROM PYTHON SOURCE LINES 18-24

Basic logic
---------------
As we show in :ref:`small_darcy_vis`, we apply a 2d grid positional encoding to our data before passing it into the FNO. 
This embedding has been shown to improve model performance in a variety of applications. 
Let's walk through its use. We start with a function that gives the coordinates of the bottom-left corners of each pixel in a grid:
%%

.. GENERATED FROM PYTHON SOURCE LINES 24-30

.. code-block:: Python

    from neuralop.layers.embeddings import regular_grid_2d
    grid_2d = torch.stack(regular_grid_2d(spatial_dims=(8,8))).permute(1,2,0).view(-1,2) #reshape into (64, 2)

    plt.scatter(grid_2d[:, 0], grid_2d[:, 1], color='orange', label="2d regular grid")
    plt.legend()




.. image-sg:: /auto_examples/layers/images/sphx_glr_plot_embeddings_001.png
   :alt: plot embeddings
   :srcset: /auto_examples/layers/images/sphx_glr_plot_embeddings_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <matplotlib.legend.Legend object at 0x7ff94d27b390>



.. GENERATED FROM PYTHON SOURCE LINES 31-35

Applying embedding to data
---------------------------
In practice, we concatenate these two channels, representing the x- and y-coordinates of each pixel in an example, 
after the channels which encode physical variables in our PDE problems:

.. GENERATED FROM PYTHON SOURCE LINES 35-72

.. code-block:: Python

    from neuralop.data.datasets import load_darcy_flow_small
    from neuralop.layers.embeddings import GridEmbedding2D

    _, test_loaders, _ = load_darcy_flow_small(
            n_train=10, batch_size=1, 
            test_resolutions=[16, 32], n_tests=[16, 16],
            test_batch_sizes=[2, 2], 
            encode_output=False
    )

    loader_16 = test_loaders[16]
    example = next(iter(loader_16))
    x = example['x']
    print(f"One batch of x is of shape: {x.shape}")

    # Note: our Darcy dataset is generated on the unit square, but our grid 
    # embedding's boundaries are configurable.
    grid_embedding = GridEmbedding2D(in_channels=1, grid_boundaries=[[0,1], [0,1]])
    x = grid_embedding(x)
    print(f"After embedding, x is of shape: {x.shape}")

    # grab the first element of the batch
    x = x[0]
    fig = plt.figure(figsize=(7, 7))
    ax = fig.add_subplot(2, 2, 1)
    ax.imshow(x[0], cmap='gray')
    ax.set_title('input x')
    ax = fig.add_subplot(2, 2, 3)
    ax.imshow(x[1])
    ax.set_title('x: 1st pos embedding')
    ax = fig.add_subplot(2, 2, 4)
    ax.imshow(x[2])
    ax.set_title('x: 2nd pos embedding')
    fig.suptitle('Visualizing one 16x16 input sample', y=0.98)
    plt.tight_layout()
    fig.show()




.. image-sg:: /auto_examples/layers/images/sphx_glr_plot_embeddings_002.png
   :alt: Visualizing one 16x16 input sample, input x, x: 1st pos embedding, x: 2nd pos embedding
   :srcset: /auto_examples/layers/images/sphx_glr_plot_embeddings_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Loading test db for resolution 16 with 16 samples 
    Loading test db for resolution 32 with 16 samples 
    /opt/hostedtoolcache/Python/3.13.5/x64/lib/python3.13/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.
      warnings.warn(warn_msg)
    One batch of x is of shape: torch.Size([2, 1, 16, 16])
    After embedding, x is of shape: torch.Size([2, 3, 16, 16])




.. GENERATED FROM PYTHON SOURCE LINES 73-75

Our embeddings are also designed with discretization-invariance in mind.
Without any changes, we can apply the same embedding to higher-resolution data:

.. GENERATED FROM PYTHON SOURCE LINES 75-99

.. code-block:: Python


    loader_32 = test_loaders[32]
    example = next(iter(loader_32))
    x = example['x']
    print(f"One batch of x is of shape: {x.shape}")

    x = grid_embedding(x)
    print(f"After embedding, x is of shape: {x.shape}")

    # grab the first element of the batch
    x = x[0]
    fig = plt.figure(figsize=(7, 7))
    ax = fig.add_subplot(2, 2, 1)
    ax.imshow(x[0], cmap='gray')
    ax.set_title('input x')
    ax = fig.add_subplot(2, 2, 3)
    ax.imshow(x[1])
    ax.set_title('x: 1st pos embedding')
    ax = fig.add_subplot(2, 2, 4)
    ax.imshow(x[2])
    ax.set_title('x: 2nd pos embedding')
    fig.suptitle('Visualizing one 32x32 input sample', y=0.98)
    plt.tight_layout()
    fig.show()



.. image-sg:: /auto_examples/layers/images/sphx_glr_plot_embeddings_003.png
   :alt: Visualizing one 32x32 input sample, input x, x: 1st pos embedding, x: 2nd pos embedding
   :srcset: /auto_examples/layers/images/sphx_glr_plot_embeddings_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    One batch of x is of shape: torch.Size([2, 1, 32, 32])
    After embedding, x is of shape: torch.Size([2, 3, 32, 32])




.. GENERATED FROM PYTHON SOURCE LINES 100-103

%%
Let's also embed a 3d tensor.
Assuming we have one channel of data discretized on a 5x5x5 cube:

.. GENERATED FROM PYTHON SOURCE LINES 103-118

.. code-block:: Python

    from neuralop.layers.embeddings import GridEmbeddingND
    cube_len = 5
    x = torch.randn(1, 1, cube_len, cube_len, cube_len)
    embedding_3d = GridEmbeddingND(in_channels=1, dim=3, grid_boundaries=[[0,1]]*3)

    x = embedding_3d(x)
    # grab only the appended positional embedding channels
    x = x[0,1:,...].permute(1,2,3,0).view(-1, 3)
    fig, ax = plt.subplots(subplot_kw={"projection": "3d"})
    plot = ax.scatter(x[:,0], x[:, 1], x[:, 2], c=x[:, 2])
    fig.colorbar(plot, ax=ax, shrink=0.6)
    ax.set_title("3d positional encoding, color=Z value")
    ax.set_xlabel("X")
    ax.set_ylabel("Y")
    ax.set_zlabel("Z")



.. image-sg:: /auto_examples/layers/images/sphx_glr_plot_embeddings_004.png
   :alt: 3d positional encoding, color=Z value
   :srcset: /auto_examples/layers/images/sphx_glr_plot_embeddings_004.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Text(0.10787434422876359, 0.014452421710066976, 'Z')




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 1.290 seconds)


.. _sphx_glr_download_auto_examples_layers_plot_embeddings.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_embeddings.ipynb <plot_embeddings.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_embeddings.py <plot_embeddings.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_embeddings.zip <plot_embeddings.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
